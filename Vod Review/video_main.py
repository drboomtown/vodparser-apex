import cv2
import threading
import logging
from imutils.video import FPS
from collections import defaultdict
from video_edit import get_meta_cv, get_meta, get_frame_data, cut_clip_ms, merge_clips
from video_processing import cv_processing, reduction_det_ms, group_det_ms


class ApexVod():
    """This class covers all the main processing of the video file"""

    def __init__(self):
        # initialises a few global variables
        self.frame_data = defaultdict(list)
        self.frame_count = 0
        self.health_bar_coord = None
        # set to True to show more detailed outputs in the console
        # also displays frames as viewed by the program and how they are proccessing
        self.debug = False
        # loading the reference image to be used in digit reading
        self.ref = cv2.imread("Reference.png", cv2.IMREAD_GRAYSCALE)

    def proccess_vod(self,
                     ref,
                     frame_data,
                     frame_count,
                     health_bar_coord,
                     filename,
                     output,
                     kill_only,
                     merge,
                     frame_skip,
                     det_range,
                     buffer,
                     debug,
                     accuracy=False):

        # loads the video file into opencv
        vid = cv2.VideoCapture(filename, cv2.CAP_ANY)

        # if accuracy option is selected this calls ffprobe to generate meta data of the video
        if accuracy is True:
            meta = get_meta(filename)
        # fast option uses opencv to generate meta data, very minor differences between the two
        # with further testing i might just reduce this to the fast option only if there is no negative effect on output
        else:
            meta = get_meta_cv(vid)

        # starts a timer for how long it takes to process the video
        if debug is True:
            fps = FPS().start()

        # if accuracy option is selected in the GUI this calls ffprobe to give accurate time stamps per frame
        # otherwise if fast is selected we use the timestamps generated by opencv.
        # 90% of the time the fast option results are close enough and not noticeable
        # but in certain variable frame rate videos the accurate method is needed for good outputs
        if accuracy is True:
            thread1 = threading.Thread(target=get_frame_data, args=(filename,
                                                                    frame_data))

        # this function is the bulk of the code,
        # it processes the video frames and outputs a list of frames with info of what is detected in said frame
        # this and the accurate frame data are spawned in separate threads to allow for simultaneous processing
        logging.info(f'processing start')
        thread2 = threading.Thread(target=cv_processing, args=(frame_skip,
                                                               meta,
                                                               debug,
                                                               frame_data,
                                                               frame_count,
                                                               health_bar_coord,
                                                               vid,
                                                               ref,
                                                               kill_only,
                                                               accuracy))

        # starting the threads
        if accuracy is True:
            thread1.start()
        thread2.start()

        # waiting for both threads to finish before proceeding
        if accuracy is True:
            thread1.join()
        thread2.join()
        logging.info(f'processing finished')

        # releasing the video from memory
        vid.release()
        # destroying any active windows showing on screen
        cv2.destroyAllWindows()

        # calling function to compare a frame to the previous frame and detect if certain parameters have been met
        # eg. health reducing, ammo reducing, or frame marker on screen
        final_det = reduction_det_ms(frame_data)

        # calling the reduction function to group together detections within the set range
        cut_list = group_det_ms(final_det,
                                debug,
                                det_range)

        # calling in the function that cuts the input video file per previously grouped detections
        # also returns the name of those files for merging
        merge_list = cut_clip_ms(cut_list,
                                 buffer,
                                 filename,
                                 output)

        # if merge option is ticked in GUI, calls in the merge function and concatenates all previously cut clips
        if merge is True:
            merge_clips(filename,
                        merge_list,
                        output)
        if debug is True:
            fps.stop()
            print(f'[INFO] clip duration: {meta[3]}')
            print("[INFO] elapsed time: {:.2f}".format(fps.elapsed()))
            print("[INFO] approx. FPS: {:.2f}".format(fps.fps()))
